digraph {
	graph [size="151.95,151.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140422218542032 [label="
 (64, 1000)" fillcolor=darkolivegreen1]
	140422032582544 [label=AddmmBackward0]
	140422032581152 -> 140422032582544
	140422216756976 [label="fc.bias
 (1000)" fillcolor=lightblue]
	140422216756976 -> 140422032581152
	140422032581152 [label=AccumulateGrad]
	140422032582160 -> 140422032582544
	140422032582160 [label=ReshapeAliasBackward0]
	140422032098016 -> 140422032582160
	140422032098016 [label=MeanBackward1]
	140422032100560 -> 140422032098016
	140422032100560 [label=ReluBackward0]
	140422033946272 -> 140422032100560
	140422033946272 [label=AddBackward0]
	140422218143632 -> 140422033946272
	140422218143632 [label=CudnnBatchNormBackward0]
	140422218144880 -> 140422218143632
	140422218144880 [label=CudnnConvolutionBackward0]
	140422218143488 -> 140422218144880
	140422218143488 [label=ReluBackward0]
	140422218142384 -> 140422218143488
	140422218142384 [label=CudnnBatchNormBackward0]
	140422218141760 -> 140422218142384
	140422218141760 [label=CudnnConvolutionBackward0]
	140422218142768 -> 140422218141760
	140422218142768 [label=ReluBackward0]
	140422218142480 -> 140422218142768
	140422218142480 [label=CudnnBatchNormBackward0]
	140422218142240 -> 140422218142480
	140422218142240 [label=CudnnConvolutionBackward0]
	140422218144544 -> 140422218142240
	140422218144544 [label=ReluBackward0]
	140422218143920 -> 140422218144544
	140422218143920 [label=AddBackward0]
	140422218144352 -> 140422218143920
	140422218144352 [label=CudnnBatchNormBackward0]
	140422218144736 -> 140422218144352
	140422218144736 [label=CudnnConvolutionBackward0]
	140422218144448 -> 140422218144736
	140422218144448 [label=ReluBackward0]
	140422218142096 -> 140422218144448
	140422218142096 [label=CudnnBatchNormBackward0]
	140422218145216 -> 140422218142096
	140422218145216 [label=CudnnConvolutionBackward0]
	140422218145168 -> 140422218145216
	140422218145168 [label=ReluBackward0]
	140422218144832 -> 140422218145168
	140422218144832 [label=CudnnBatchNormBackward0]
	140422218144592 -> 140422218144832
	140422218144592 [label=CudnnConvolutionBackward0]
	140422218144304 -> 140422218144592
	140422218144304 [label=ReluBackward0]
	140422218142432 -> 140422218144304
	140422218142432 [label=AddBackward0]
	140422218143872 -> 140422218142432
	140422218143872 [label=CudnnBatchNormBackward0]
	140422218144160 -> 140422218143872
	140422218144160 [label=CudnnConvolutionBackward0]
	140422218065712 -> 140422218144160
	140422218065712 [label=ReluBackward0]
	140422218065088 -> 140422218065712
	140422218065088 [label=CudnnBatchNormBackward0]
	140422218064560 -> 140422218065088
	140422218064560 [label=CudnnConvolutionBackward0]
	140422218064320 -> 140422218064560
	140422218064320 [label=ReluBackward0]
	140422218064464 -> 140422218064320
	140422218064464 [label=CudnnBatchNormBackward0]
	140422218064032 -> 140422218064464
	140422218064032 [label=CudnnConvolutionBackward0]
	140422218066288 -> 140422218064032
	140422218066288 [label=ReluBackward0]
	140422218066432 -> 140422218066288
	140422218066432 [label=AddBackward0]
	140422218066768 -> 140422218066432
	140422218066768 [label=CudnnBatchNormBackward0]
	140422218065808 -> 140422218066768
	140422218065808 [label=CudnnConvolutionBackward0]
	140422218065904 -> 140422218065808
	140422218065904 [label=ReluBackward0]
	140422218065568 -> 140422218065904
	140422218065568 [label=CudnnBatchNormBackward0]
	140422218065232 -> 140422218065568
	140422218065232 [label=CudnnConvolutionBackward0]
	140422218065136 -> 140422218065232
	140422218065136 [label=ReluBackward0]
	140422218066576 -> 140422218065136
	140422218066576 [label=CudnnBatchNormBackward0]
	140422218066816 -> 140422218066576
	140422218066816 [label=CudnnConvolutionBackward0]
	140422218066096 -> 140422218066816
	140422218066096 [label=ReluBackward0]
	140422218067776 -> 140422218066096
	140422218067776 [label=AddBackward0]
	140422218065376 -> 140422218067776
	140422218065376 [label=CudnnBatchNormBackward0]
	140422218067104 -> 140422218065376
	140422218067104 [label=CudnnConvolutionBackward0]
	140422218067008 -> 140422218067104
	140422218067008 [label=ReluBackward0]
	140422218064176 -> 140422218067008
	140422218064176 [label=CudnnBatchNormBackward0]
	140422218064608 -> 140422218064176
	140422218064608 [label=CudnnConvolutionBackward0]
	140422218064944 -> 140422218064608
	140422218064944 [label=ReluBackward0]
	140422218096016 -> 140422218064944
	140422218096016 [label=CudnnBatchNormBackward0]
	140422218092896 -> 140422218096016
	140422218092896 [label=CudnnConvolutionBackward0]
	140422218067392 -> 140422218092896
	140422218067392 [label=ReluBackward0]
	140422218095680 -> 140422218067392
	140422218095680 [label=AddBackward0]
	140422218095440 -> 140422218095680
	140422218095440 [label=CudnnBatchNormBackward0]
	140422218093568 -> 140422218095440
	140422218093568 [label=CudnnConvolutionBackward0]
	140422218093760 -> 140422218093568
	140422218093760 [label=ReluBackward0]
	140422218094576 -> 140422218093760
	140422218094576 [label=CudnnBatchNormBackward0]
	140422218094672 -> 140422218094576
	140422218094672 [label=CudnnConvolutionBackward0]
	140422218092704 -> 140422218094672
	140422218092704 [label=ReluBackward0]
	140422218093136 -> 140422218092704
	140422218093136 [label=CudnnBatchNormBackward0]
	140422218092800 -> 140422218093136
	140422218092800 [label=CudnnConvolutionBackward0]
	140422218095392 -> 140422218092800
	140422218095392 [label=ReluBackward0]
	140422218094864 -> 140422218095392
	140422218094864 [label=AddBackward0]
	140422218094288 -> 140422218094864
	140422218094288 [label=CudnnBatchNormBackward0]
	140422218094432 -> 140422218094288
	140422218094432 [label=CudnnConvolutionBackward0]
	140422218095008 -> 140422218094432
	140422218095008 [label=ReluBackward0]
	140422218093328 -> 140422218095008
	140422218093328 [label=CudnnBatchNormBackward0]
	140422218093376 -> 140422218093328
	140422218093376 [label=CudnnConvolutionBackward0]
	140422218094720 -> 140422218093376
	140422218094720 [label=ReluBackward0]
	140422218096352 -> 140422218094720
	140422218096352 [label=CudnnBatchNormBackward0]
	140422218096064 -> 140422218096352
	140422218096064 [label=CudnnConvolutionBackward0]
	140422218094336 -> 140422218096064
	140422218094336 [label=ReluBackward0]
	140422218095824 -> 140422218094336
	140422218095824 [label=AddBackward0]
	140422218095488 -> 140422218095824
	140422218095488 [label=CudnnBatchNormBackward0]
	140422218095200 -> 140422218095488
	140422218095200 [label=CudnnConvolutionBackward0]
	140422218095104 -> 140422218095200
	140422218095104 [label=ReluBackward0]
	140422218095152 -> 140422218095104
	140422218095152 [label=CudnnBatchNormBackward0]
	140422218122960 -> 140422218095152
	140422218122960 [label=CudnnConvolutionBackward0]
	140422218124640 -> 140422218122960
	140422218124640 [label=ReluBackward0]
	140422218124784 -> 140422218124640
	140422218124784 [label=CudnnBatchNormBackward0]
	140422218125120 -> 140422218124784
	140422218125120 [label=CudnnConvolutionBackward0]
	140422218095872 -> 140422218125120
	140422218095872 [label=ReluBackward0]
	140422218124208 -> 140422218095872
	140422218124208 [label=AddBackward0]
	140422218123872 -> 140422218124208
	140422218123872 [label=CudnnBatchNormBackward0]
	140422218123968 -> 140422218123872
	140422218123968 [label=CudnnConvolutionBackward0]
	140422218123680 -> 140422218123968
	140422218123680 [label=ReluBackward0]
	140422218125168 -> 140422218123680
	140422218125168 [label=CudnnBatchNormBackward0]
	140422218125024 -> 140422218125168
	140422218125024 [label=CudnnConvolutionBackward0]
	140422218121424 -> 140422218125024
	140422218121424 [label=ReluBackward0]
	140422218121328 -> 140422218121424
	140422218121328 [label=CudnnBatchNormBackward0]
	140422218121952 -> 140422218121328
	140422218121952 [label=CudnnConvolutionBackward0]
	140422218122432 -> 140422218121952
	140422218122432 [label=ReluBackward0]
	140422218123056 -> 140422218122432
	140422218123056 [label=AddBackward0]
	140422218124400 -> 140422218123056
	140422218124400 [label=CudnnBatchNormBackward0]
	140422218124304 -> 140422218124400
	140422218124304 [label=CudnnConvolutionBackward0]
	140422218121376 -> 140422218124304
	140422218121376 [label=ReluBackward0]
	140422218122864 -> 140422218121376
	140422218122864 [label=CudnnBatchNormBackward0]
	140422218122576 -> 140422218122864
	140422218122576 [label=CudnnConvolutionBackward0]
	140422218122288 -> 140422218122576
	140422218122288 [label=ReluBackward0]
	140422218122336 -> 140422218122288
	140422218122336 [label=CudnnBatchNormBackward0]
	140422218122000 -> 140422218122336
	140422218122000 [label=CudnnConvolutionBackward0]
	140422218123296 -> 140422218122000
	140422218123296 [label=ReluBackward0]
	140422218121760 -> 140422218123296
	140422218121760 [label=AddBackward0]
	140422218121616 -> 140422218121760
	140422218121616 [label=CudnnBatchNormBackward0]
	140427244783024 -> 140422218121616
	140427244783024 [label=CudnnConvolutionBackward0]
	140422218277552 -> 140427244783024
	140422218277552 [label=ReluBackward0]
	140422218277408 -> 140422218277552
	140422218277408 [label=CudnnBatchNormBackward0]
	140422218279952 -> 140422218277408
	140422218279952 [label=CudnnConvolutionBackward0]
	140422218278128 -> 140422218279952
	140422218278128 [label=ReluBackward0]
	140422218279520 -> 140422218278128
	140422218279520 [label=CudnnBatchNormBackward0]
	140422218280480 -> 140422218279520
	140422218280480 [label=CudnnConvolutionBackward0]
	140422218121808 -> 140422218280480
	140422218121808 [label=ReluBackward0]
	140422218279040 -> 140422218121808
	140422218279040 [label=AddBackward0]
	140422218278512 -> 140422218279040
	140422218278512 [label=CudnnBatchNormBackward0]
	140422218278896 -> 140422218278512
	140422218278896 [label=CudnnConvolutionBackward0]
	140422218278560 -> 140422218278896
	140422218278560 [label=ReluBackward0]
	140422218279664 -> 140422218278560
	140422218279664 [label=CudnnBatchNormBackward0]
	140422218280624 -> 140422218279664
	140422218280624 [label=CudnnConvolutionBackward0]
	140422218278992 -> 140422218280624
	140422218278992 [label=ReluBackward0]
	140422218279712 -> 140422218278992
	140422218279712 [label=CudnnBatchNormBackward0]
	140422218278032 -> 140422218279712
	140422218278032 [label=CudnnConvolutionBackward0]
	140422218280000 -> 140422218278032
	140422218280000 [label=ReluBackward0]
	140422218277600 -> 140422218280000
	140422218277600 [label=AddBackward0]
	140422218278752 -> 140422218277600
	140422218278752 [label=CudnnBatchNormBackward0]
	140422218280528 -> 140422218278752
	140422218280528 [label=CudnnConvolutionBackward0]
	140422218280432 -> 140422218280528
	140422218280432 [label=ReluBackward0]
	140422218280672 -> 140422218280432
	140422218280672 [label=CudnnBatchNormBackward0]
	140422218277120 -> 140422218280672
	140422218277120 [label=CudnnConvolutionBackward0]
	140427244417520 -> 140422218277120
	140427244417520 [label=ReluBackward0]
	140427244417904 -> 140427244417520
	140427244417904 [label=CudnnBatchNormBackward0]
	140427244417136 -> 140427244417904
	140427244417136 [label=CudnnConvolutionBackward0]
	140422218036032 -> 140427244417136
	140422218036032 [label=ReluBackward0]
	140422218035792 -> 140422218036032
	140422218035792 [label=AddBackward0]
	140422218035888 -> 140422218035792
	140422218035888 [label=CudnnBatchNormBackward0]
	140422218035984 -> 140422218035888
	140422218035984 [label=CudnnConvolutionBackward0]
	140422218035600 -> 140422218035984
	140422218035600 [label=ReluBackward0]
	140422218036320 -> 140422218035600
	140422218036320 [label=CudnnBatchNormBackward0]
	140422218036272 -> 140422218036320
	140422218036272 [label=CudnnConvolutionBackward0]
	140422218039248 -> 140422218036272
	140422218039248 [label=ReluBackward0]
	140422218037040 -> 140422218039248
	140422218037040 [label=CudnnBatchNormBackward0]
	140422218038096 -> 140422218037040
	140422218038096 [label=CudnnConvolutionBackward0]
	140422218035840 -> 140422218038096
	140422218035840 [label=ReluBackward0]
	140422218038576 -> 140422218035840
	140422218038576 [label=AddBackward0]
	140422218038048 -> 140422218038576
	140422218038048 [label=CudnnBatchNormBackward0]
	140422218037856 -> 140422218038048
	140422218037856 [label=CudnnConvolutionBackward0]
	140422218037952 -> 140422218037856
	140422218037952 [label=ReluBackward0]
	140422218037136 -> 140422218037952
	140422218037136 [label=CudnnBatchNormBackward0]
	140422218037184 -> 140422218037136
	140422218037184 [label=CudnnConvolutionBackward0]
	140422218036896 -> 140422218037184
	140422218036896 [label=ReluBackward0]
	140422218036656 -> 140422218036896
	140422218036656 [label=CudnnBatchNormBackward0]
	140422218039008 -> 140422218036656
	140422218039008 [label=CudnnConvolutionBackward0]
	140422218038000 -> 140422218039008
	140422218038000 [label=ReluBackward0]
	140422218038624 -> 140422218038000
	140422218038624 [label=AddBackward0]
	140422218037280 -> 140422218038624
	140422218037280 [label=CudnnBatchNormBackward0]
	140422218036992 -> 140422218037280
	140422218036992 [label=CudnnConvolutionBackward0]
	140422218038960 -> 140422218036992
	140422218038960 [label=ReluBackward0]
	140422218038432 -> 140422218038960
	140422218038432 [label=CudnnBatchNormBackward0]
	140422218039200 -> 140422218038432
	140422218039200 [label=CudnnConvolutionBackward0]
	140422218036560 -> 140422218039200
	140422218036560 [label=ReluBackward0]
	140422218036704 -> 140422218036560
	140422218036704 [label=CudnnBatchNormBackward0]
	140422218175584 -> 140422218036704
	140422218175584 [label=CudnnConvolutionBackward0]
	140422218178464 -> 140422218175584
	140422218178464 [label=MaxPool2DWithIndicesBackward0]
	140422218176544 -> 140422218178464
	140422218176544 [label=ReluBackward0]
	140422218178128 -> 140422218176544
	140422218178128 [label=CudnnBatchNormBackward0]
	140422218175008 -> 140422218178128
	140422218175008 [label=CudnnConvolutionBackward0]
	140422218174816 -> 140422218175008
	140422033679440 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	140422033679440 -> 140422218174816
	140422218174816 [label=AccumulateGrad]
	140422218177936 -> 140422218178128
	140422216664064 [label="bn1.weight
 (64)" fillcolor=lightblue]
	140422216664064 -> 140422218177936
	140422218177936 [label=AccumulateGrad]
	140422218175968 -> 140422218178128
	140422216665984 [label="bn1.bias
 (64)" fillcolor=lightblue]
	140422216665984 -> 140422218175968
	140422218175968 [label=AccumulateGrad]
	140422218177840 -> 140422218175584
	140422032802176 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	140422032802176 -> 140422218177840
	140422218177840 [label=AccumulateGrad]
	140422218176256 -> 140422218036704
	140422032802496 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	140422032802496 -> 140422218176256
	140422218176256 [label=AccumulateGrad]
	140422218177264 -> 140422218036704
	140422032803616 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	140422032803616 -> 140422218177264
	140422218177264 [label=AccumulateGrad]
	140422218035408 -> 140422218039200
	140422032802736 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140422032802736 -> 140422218035408
	140422218035408 [label=AccumulateGrad]
	140422218039152 -> 140422218038432
	140422032802096 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	140422032802096 -> 140422218039152
	140422218039152 [label=AccumulateGrad]
	140422218037568 -> 140422218038432
	140422032801856 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	140422032801856 -> 140422218037568
	140422218037568 [label=AccumulateGrad]
	140422218037616 -> 140422218036992
	140422033520416 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140422033520416 -> 140422218037616
	140422218037616 [label=AccumulateGrad]
	140422218037376 -> 140422218037280
	140422033518896 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	140422033518896 -> 140422218037376
	140422218037376 [label=AccumulateGrad]
	140422218037328 -> 140422218037280
	140422033522496 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	140422033522496 -> 140422218037328
	140422218037328 [label=AccumulateGrad]
	140422218038672 -> 140422218038624
	140422218038672 [label=CudnnBatchNormBackward0]
	140422218035264 -> 140422218038672
	140422218035264 [label=CudnnConvolutionBackward0]
	140422218178464 -> 140422218035264
	140422218038192 -> 140422218035264
	140422032838464 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140422032838464 -> 140422218038192
	140422218038192 [label=AccumulateGrad]
	140422218037664 -> 140422218038672
	140422032838544 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	140422032838544 -> 140422218037664
	140422218037664 [label=AccumulateGrad]
	140422218038336 -> 140422218038672
	140422032835344 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	140422032835344 -> 140422218038336
	140422218038336 [label=AccumulateGrad]
	140422218038768 -> 140422218039008
	140422033519136 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140422033519136 -> 140422218038768
	140422218038768 [label=AccumulateGrad]
	140422218038240 -> 140422218036656
	140422032969616 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	140422032969616 -> 140422218038240
	140422218038240 [label=AccumulateGrad]
	140422218036944 -> 140422218036656
	140422032969536 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	140422032969536 -> 140422218036944
	140422218036944 [label=AccumulateGrad]
	140422218038144 -> 140422218037184
	140422032968656 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140422032968656 -> 140422218038144
	140422218038144 [label=AccumulateGrad]
	140422218038528 -> 140422218037136
	140422032969456 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	140422032969456 -> 140422218038528
	140422218038528 [label=AccumulateGrad]
	140422218037472 -> 140422218037136
	140422032969136 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	140422032969136 -> 140422218037472
	140422218037472 [label=AccumulateGrad]
	140422218037760 -> 140422218037856
	140422032967776 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140422032967776 -> 140422218037760
	140422218037760 [label=AccumulateGrad]
	140422218038384 -> 140422218038048
	140422032967456 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	140422032967456 -> 140422218038384
	140422218038384 [label=AccumulateGrad]
	140422218037712 -> 140422218038048
	140422032967856 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	140422032967856 -> 140422218037712
	140422218037712 [label=AccumulateGrad]
	140422218038000 -> 140422218038576
	140422218036752 -> 140422218038096
	140422032968016 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	140422032968016 -> 140422218036752
	140422218036752 [label=AccumulateGrad]
	140422218038288 -> 140422218037040
	140422032966736 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	140422032966736 -> 140422218038288
	140422218038288 [label=AccumulateGrad]
	140422218038864 -> 140422218037040
	140422032968816 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	140422032968816 -> 140422218038864
	140422218038864 [label=AccumulateGrad]
	140422218036080 -> 140422218036272
	140422032968256 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140422032968256 -> 140422218036080
	140422218036080 [label=AccumulateGrad]
	140422218036224 -> 140422218036320
	140422032966816 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	140422032966816 -> 140422218036224
	140422218036224 [label=AccumulateGrad]
	140422218036416 -> 140422218036320
	140422216903472 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	140422216903472 -> 140422218036416
	140422218036416 [label=AccumulateGrad]
	140422218035648 -> 140422218035984
	140422216900672 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	140422216900672 -> 140422218035648
	140422218035648 [label=AccumulateGrad]
	140422218035936 -> 140422218035888
	140422216901152 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	140422216901152 -> 140422218035936
	140422218035936 [label=AccumulateGrad]
	140422218035504 -> 140422218035888
	140422216900992 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	140422216900992 -> 140422218035504
	140422218035504 [label=AccumulateGrad]
	140422218035840 -> 140422218035792
	140422218036608 -> 140427244417136
	140422216904352 [label="layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	140422216904352 -> 140422218036608
	140422218036608 [label=AccumulateGrad]
	140427244417616 -> 140427244417904
	140422216903312 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	140422216903312 -> 140427244417616
	140427244417616 [label=AccumulateGrad]
	140427244417856 -> 140427244417904
	140422216903392 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	140422216903392 -> 140427244417856
	140427244417856 [label=AccumulateGrad]
	140427244417232 -> 140422218277120
	140422034099152 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140422034099152 -> 140427244417232
	140427244417232 [label=AccumulateGrad]
	140422218279904 -> 140422218280672
	140422216900752 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	140422216900752 -> 140422218279904
	140422218279904 [label=AccumulateGrad]
	140422218280288 -> 140422218280672
	140422034100112 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	140422034100112 -> 140422218280288
	140422218280288 [label=AccumulateGrad]
	140422218277888 -> 140422218280528
	140422034098992 [label="layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140422034098992 -> 140422218277888
	140422218277888 [label=AccumulateGrad]
	140422218279568 -> 140422218278752
	140422034098192 [label="layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	140422034098192 -> 140422218279568
	140422218279568 [label=AccumulateGrad]
	140422218280912 -> 140422218278752
	140422034098912 [label="layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	140422034098912 -> 140422218280912
	140422218280912 [label=AccumulateGrad]
	140422218276928 -> 140422218277600
	140422218276928 [label=CudnnBatchNormBackward0]
	140422218278416 -> 140422218276928
	140422218278416 [label=CudnnConvolutionBackward0]
	140422218036032 -> 140422218278416
	140427244417424 -> 140422218278416
	140422216903632 [label="layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140422216903632 -> 140427244417424
	140427244417424 [label=AccumulateGrad]
	140422218280576 -> 140422218276928
	140422216903792 [label="layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	140422216903792 -> 140422218280576
	140422218280576 [label=AccumulateGrad]
	140422218278800 -> 140422218276928
	140422216903952 [label="layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	140422216903952 -> 140422218278800
	140422218278800 [label=AccumulateGrad]
	140422218278848 -> 140422218278032
	140422034099712 [label="layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140422034099712 -> 140422218278848
	140422218278848 [label=AccumulateGrad]
	140422218280192 -> 140422218279712
	140422034098032 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	140422034098032 -> 140422218280192
	140422218280192 [label=AccumulateGrad]
	140422218280720 -> 140422218279712
	140422034099312 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	140422034099312 -> 140422218280720
	140422218280720 [label=AccumulateGrad]
	140422218280768 -> 140422218280624
	140422032397552 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140422032397552 -> 140422218280768
	140422218280768 [label=AccumulateGrad]
	140422218278608 -> 140422218279664
	140422034099792 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	140422034099792 -> 140422218278608
	140422218278608 [label=AccumulateGrad]
	140422218279184 -> 140422218279664
	140422032396832 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	140422032396832 -> 140422218279184
	140422218279184 [label=AccumulateGrad]
	140422218280096 -> 140422218278896
	140422032399472 [label="layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140422032399472 -> 140422218280096
	140422218280096 [label=AccumulateGrad]
	140422218279376 -> 140422218278512
	140422032398912 [label="layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	140422032398912 -> 140422218279376
	140422218279376 [label=AccumulateGrad]
	140422218278944 -> 140422218278512
	140422032399872 [label="layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	140422032399872 -> 140422218278944
	140422218278944 [label=AccumulateGrad]
	140422218280000 -> 140422218279040
	140422218279088 -> 140422218280480
	140422032397072 [label="layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140422032397072 -> 140422218279088
	140422218279088 [label=AccumulateGrad]
	140422218279616 -> 140422218279520
	140422032399632 [label="layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	140422032399632 -> 140422218279616
	140422218279616 [label=AccumulateGrad]
	140422218277264 -> 140422218279520
	140422032396432 [label="layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	140422032396432 -> 140422218277264
	140422218277264 [label=AccumulateGrad]
	140422218277792 -> 140422218279952
	140422032397472 [label="layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140422032397472 -> 140422218277792
	140422218277792 [label=AccumulateGrad]
	140422218278464 -> 140422218277408
	140422032399552 [label="layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	140422032399552 -> 140422218278464
	140422218278464 [label=AccumulateGrad]
	140422218276976 -> 140422218277408
	140422032396352 [label="layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	140422032396352 -> 140422218276976
	140422218276976 [label=AccumulateGrad]
	140422218279232 -> 140427244783024
	140422032398752 [label="layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140422032398752 -> 140422218279232
	140422218279232 [label=AccumulateGrad]
	140427244899632 -> 140422218121616
	140422032397232 [label="layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	140422032397232 -> 140427244899632
	140427244899632 [label=AccumulateGrad]
	140422218121664 -> 140422218121616
	140422032398672 [label="layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	140422032398672 -> 140422218121664
	140422218121664 [label=AccumulateGrad]
	140422218121808 -> 140422218121760
	140422218121712 -> 140422218122000
	140422032398352 [label="layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	140422032398352 -> 140422218121712
	140422218121712 [label=AccumulateGrad]
	140422218122384 -> 140422218122336
	140422032399392 [label="layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	140422032399392 -> 140422218122384
	140422218122384 [label=AccumulateGrad]
	140422218122624 -> 140422218122336
	140422032398512 [label="layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	140422032398512 -> 140422218122624
	140422218122624 [label=AccumulateGrad]
	140422218122672 -> 140422218122576
	140422032397392 [label="layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140422032397392 -> 140422218122672
	140422218122672 [label=AccumulateGrad]
	140422218122912 -> 140422218122864
	140422032396912 [label="layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	140422032396912 -> 140422218122912
	140422218122912 [label=AccumulateGrad]
	140422218122768 -> 140422218122864
	140422032397152 [label="layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	140422032397152 -> 140422218122768
	140422218122768 [label=AccumulateGrad]
	140422218121568 -> 140422218124304
	140422032396592 [label="layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	140422032396592 -> 140422218121568
	140422218121568 [label=AccumulateGrad]
	140422218124064 -> 140422218124400
	140422032494976 [label="layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	140422032494976 -> 140422218124064
	140422218124064 [label=AccumulateGrad]
	140422218124016 -> 140422218124400
	140422032495136 [label="layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	140422032495136 -> 140422218124016
	140422218124016 [label=AccumulateGrad]
	140422218123296 -> 140422218123056
	140422218121856 -> 140422218121952
	140422032495616 [label="layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	140422032495616 -> 140422218121856
	140422218121856 [label=AccumulateGrad]
	140422218122240 -> 140422218121328
	140422032494736 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	140422032494736 -> 140422218122240
	140422218122240 [label=AccumulateGrad]
	140422218121472 -> 140422218121328
	140422032495456 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	140422032495456 -> 140422218121472
	140422218121472 [label=AccumulateGrad]
	140422218125072 -> 140422218125024
	140422032495696 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140422032495696 -> 140422218125072
	140422218125072 [label=AccumulateGrad]
	140422218124928 -> 140422218125168
	140422032496016 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	140422032496016 -> 140422218124928
	140422218124928 [label=AccumulateGrad]
	140422218123104 -> 140422218125168
	140422032496976 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	140422032496976 -> 140422218123104
	140422218123104 [label=AccumulateGrad]
	140422218123536 -> 140422218123968
	140422032496816 [label="layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140422032496816 -> 140422218123536
	140422218123536 [label=AccumulateGrad]
	140422218123920 -> 140422218123872
	140422032496176 [label="layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	140422032496176 -> 140422218123920
	140422218123920 [label=AccumulateGrad]
	140422218124688 -> 140422218123872
	140422032497456 [label="layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	140422032497456 -> 140422218124688
	140422218124688 [label=AccumulateGrad]
	140422218124256 -> 140422218124208
	140422218124256 [label=CudnnBatchNormBackward0]
	140422218125216 -> 140422218124256
	140422218125216 [label=CudnnConvolutionBackward0]
	140422218122432 -> 140422218125216
	140422218121904 -> 140422218125216
	140422032497696 [label="layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	140422032497696 -> 140422218121904
	140422218121904 [label=AccumulateGrad]
	140422218124880 -> 140422218124256
	140422032497056 [label="layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	140422032497056 -> 140422218124880
	140422218124880 [label=AccumulateGrad]
	140422218123632 -> 140422218124256
	140422032497376 [label="layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	140422032497376 -> 140422218123632
	140422218123632 [label=AccumulateGrad]
	140422218124496 -> 140422218125120
	140422032495296 [label="layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140422032495296 -> 140422218124496
	140422218124496 [label=AccumulateGrad]
	140422218124448 -> 140422218124784
	140422032498416 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	140422032498416 -> 140422218124448
	140422218124448 [label=AccumulateGrad]
	140422218125264 -> 140422218124784
	140422032497936 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	140422032497936 -> 140422218125264
	140422218125264 [label=AccumulateGrad]
	140422218123584 -> 140422218122960
	140422032498096 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140422032498096 -> 140422218123584
	140422218123584 [label=AccumulateGrad]
	140422218122144 -> 140422218095152
	140422032494816 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	140422032494816 -> 140422218122144
	140422218122144 [label=AccumulateGrad]
	140422218122528 -> 140422218095152
	140422032497136 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	140422032497136 -> 140422218122528
	140422218122528 [label=AccumulateGrad]
	140422218095296 -> 140422218095200
	140422032495536 [label="layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140422032495536 -> 140422218095296
	140422218095296 [label=AccumulateGrad]
	140422218095584 -> 140422218095488
	140422033937648 [label="layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	140422033937648 -> 140422218095584
	140422218095584 [label=AccumulateGrad]
	140422218095536 -> 140422218095488
	140422033936928 [label="layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	140422033936928 -> 140422218095536
	140422218095536 [label=AccumulateGrad]
	140422218095872 -> 140422218095824
	140422218095776 -> 140422218096064
	140422033936448 [label="layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140422033936448 -> 140422218095776
	140422218095776 [label=AccumulateGrad]
	140422218096400 -> 140422218096352
	140422033937488 [label="layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	140422033937488 -> 140422218096400
	140422218096400 [label=AccumulateGrad]
	140422218096256 -> 140422218096352
	140422033937968 [label="layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	140422033937968 -> 140422218096256
	140422218096256 [label=AccumulateGrad]
	140422218093280 -> 140422218093376
	140422033938368 [label="layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140422033938368 -> 140422218093280
	140422218093280 [label=AccumulateGrad]
	140422218094624 -> 140422218093328
	140422033937408 [label="layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	140422033937408 -> 140422218094624
	140422218094624 [label=AccumulateGrad]
	140422218093664 -> 140422218093328
	140422033938048 [label="layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	140422033938048 -> 140422218093664
	140422218093664 [label=AccumulateGrad]
	140422218093616 -> 140422218094432
	140422033938848 [label="layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140422033938848 -> 140422218093616
	140422218093616 [label=AccumulateGrad]
	140422218094240 -> 140422218094288
	140422033939008 [label="layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	140422033939008 -> 140422218094240
	140422218094240 [label=AccumulateGrad]
	140422218093904 -> 140422218094288
	140422033939328 [label="layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	140422033939328 -> 140422218093904
	140422218093904 [label=AccumulateGrad]
	140422218094336 -> 140422218094864
	140422218094528 -> 140422218092800
	140422033939568 [label="layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140422033939568 -> 140422218094528
	140422218094528 [label=AccumulateGrad]
	140422218093184 -> 140422218093136
	140422033939648 [label="layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	140422033939648 -> 140422218093184
	140422218093184 [label=AccumulateGrad]
	140422218092656 -> 140422218093136
	140422033939088 [label="layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	140422033939088 -> 140422218092656
	140422218092656 [label=AccumulateGrad]
	140422218092752 -> 140422218094672
	140422033937248 [label="layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140422033937248 -> 140422218092752
	140422218092752 [label=AccumulateGrad]
	140422218094768 -> 140422218094576
	140422033937568 [label="layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	140422033937568 -> 140422218094768
	140422218094768 [label=AccumulateGrad]
	140422218093808 -> 140422218094576
	140422033937328 [label="layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	140422033937328 -> 140422218093808
	140422218093808 [label=AccumulateGrad]
	140422218094144 -> 140422218093568
	140422034317456 [label="layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140422034317456 -> 140422218094144
	140422218094144 [label=AccumulateGrad]
	140422218095968 -> 140422218095440
	140422034317616 [label="layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	140422034317616 -> 140422218095968
	140422218095968 [label=AccumulateGrad]
	140422218096448 -> 140422218095440
	140422034318016 [label="layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	140422034318016 -> 140422218096448
	140422218096448 [label=AccumulateGrad]
	140422218095392 -> 140422218095680
	140422218093856 -> 140422218092896
	140422034320176 [label="layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140422034320176 -> 140422218093856
	140422218093856 [label=AccumulateGrad]
	140422218095344 -> 140422218096016
	140422034320656 [label="layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	140422034320656 -> 140422218095344
	140422218095344 [label=AccumulateGrad]
	140422218093472 -> 140422218096016
	140422034320096 [label="layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	140422034320096 -> 140422218093472
	140422218093472 [label=AccumulateGrad]
	140422218064704 -> 140422218064608
	140422034317376 [label="layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140422034317376 -> 140422218064704
	140422218064704 [label=AccumulateGrad]
	140422218064992 -> 140422218064176
	140422034320816 [label="layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	140422034320816 -> 140422218064992
	140422218064992 [label=AccumulateGrad]
	140422218067056 -> 140422218064176
	140422034320336 [label="layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	140422034320336 -> 140422218067056
	140422218067056 [label=AccumulateGrad]
	140422218067200 -> 140422218067104
	140422034318656 [label="layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140422034318656 -> 140422218067200
	140422218067200 [label=AccumulateGrad]
	140422218067488 -> 140422218065376
	140422034321216 [label="layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	140422034321216 -> 140422218067488
	140422218067488 [label=AccumulateGrad]
	140422218067440 -> 140422218065376
	140422034321056 [label="layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	140422034321056 -> 140422218067440
	140422218067440 [label=AccumulateGrad]
	140422218067392 -> 140422218067776
	140422218065952 -> 140422218066816
	140422034319536 [label="layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	140422034319536 -> 140422218065952
	140422218065952 [label=AccumulateGrad]
	140422218065424 -> 140422218066576
	140422034319456 [label="layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	140422034319456 -> 140422218065424
	140422218065424 [label=AccumulateGrad]
	140422218065184 -> 140422218066576
	140422034319296 [label="layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	140422034319296 -> 140422218065184
	140422218065184 [label=AccumulateGrad]
	140422218065328 -> 140422218065232
	140422034321136 [label="layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140422034321136 -> 140422218065328
	140422218065328 [label=AccumulateGrad]
	140422218065616 -> 140422218065568
	140422034318736 [label="layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	140422034318736 -> 140422218065616
	140422218065616 [label=AccumulateGrad]
	140422218065520 -> 140422218065568
	140422034321296 [label="layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	140422034321296 -> 140422218065520
	140422218065520 [label=AccumulateGrad]
	140422218065856 -> 140422218065808
	140422034319856 [label="layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	140422034319856 -> 140422218065856
	140422218065856 [label=AccumulateGrad]
	140422218066192 -> 140422218066768
	140422034344752 [label="layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	140422034344752 -> 140422218066192
	140422218066192 [label=AccumulateGrad]
	140422218066240 -> 140422218066768
	140422034344592 [label="layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	140422034344592 -> 140422218066240
	140422218066240 [label=AccumulateGrad]
	140422218066096 -> 140422218066432
	140422218064752 -> 140422218064032
	140422034345792 [label="layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	140422034345792 -> 140422218064752
	140422218064752 [label=AccumulateGrad]
	140422218063984 -> 140422218064464
	140422034345872 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	140422034345872 -> 140422218063984
	140422218063984 [label=AccumulateGrad]
	140422218063936 -> 140422218064464
	140422034343392 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	140422034343392 -> 140422218063936
	140422218063936 [label=AccumulateGrad]
	140422218064368 -> 140422218064560
	140422034342672 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140422034342672 -> 140422218064368
	140422218064368 [label=AccumulateGrad]
	140422218064512 -> 140422218065088
	140422034342752 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	140422034342752 -> 140422218064512
	140422218064512 [label=AccumulateGrad]
	140422218064128 -> 140422218065088
	140422034342512 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	140422034342512 -> 140422218064128
	140422218064128 [label=AccumulateGrad]
	140422218066000 -> 140422218144160
	140422034341952 [label="layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	140422034341952 -> 140422218066000
	140422218066000 [label=AccumulateGrad]
	140422218067536 -> 140422218143872
	140422034342112 [label="layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	140422034342112 -> 140422218067536
	140422218067536 [label=AccumulateGrad]
	140422218065760 -> 140422218143872
	140422034342352 [label="layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	140422034342352 -> 140422218065760
	140422218065760 [label=AccumulateGrad]
	140422218143824 -> 140422218142432
	140422218143824 [label=CudnnBatchNormBackward0]
	140422218064896 -> 140422218143824
	140422218064896 [label=CudnnConvolutionBackward0]
	140422218066288 -> 140422218064896
	140422218065040 -> 140422218064896
	140422034344352 [label="layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	140422034344352 -> 140422218065040
	140422218065040 [label=AccumulateGrad]
	140422218064848 -> 140422218143824
	140422034345072 [label="layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	140422034345072 -> 140422218064848
	140422218064848 [label=AccumulateGrad]
	140422218067872 -> 140422218143824
	140422034344992 [label="layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	140422034344992 -> 140422218067872
	140422218067872 [label=AccumulateGrad]
	140422218144112 -> 140422218144592
	140422034344192 [label="layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	140422034344192 -> 140422218144112
	140422218144112 [label=AccumulateGrad]
	140422218144928 -> 140422218144832
	140422034343632 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	140422034343632 -> 140422218144928
	140422218144928 [label=AccumulateGrad]
	140422218144688 -> 140422218144832
	140422034343952 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	140422034343952 -> 140422218144688
	140422218144688 [label=AccumulateGrad]
	140422218145120 -> 140422218145216
	140422216754176 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140422216754176 -> 140422218145120
	140422218145120 [label=AccumulateGrad]
	140422218145024 -> 140422218142096
	140422216754336 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	140422216754336 -> 140422218145024
	140422218145024 [label=AccumulateGrad]
	140422218143968 -> 140422218142096
	140422216753856 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	140422216753856 -> 140422218143968
	140422218143968 [label=AccumulateGrad]
	140422218142816 -> 140422218144736
	140422216756416 [label="layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	140422216756416 -> 140422218142816
	140422218142816 [label=AccumulateGrad]
	140422218142528 -> 140422218144352
	140422216753536 [label="layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	140422216753536 -> 140422218142528
	140422218142528 [label=AccumulateGrad]
	140422218142576 -> 140422218144352
	140422216755696 [label="layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	140422216755696 -> 140422218142576
	140422218142576 [label=AccumulateGrad]
	140422218144304 -> 140422218143920
	140422218142000 -> 140422218142240
	140422216756016 [label="layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	140422216756016 -> 140422218142000
	140422218142000 [label=AccumulateGrad]
	140422218142192 -> 140422218142480
	140422216753696 [label="layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	140422216753696 -> 140422218142192
	140422218142192 [label=AccumulateGrad]
	140422218142912 -> 140422218142480
	140422216755456 [label="layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	140422216755456 -> 140422218142912
	140422218142912 [label=AccumulateGrad]
	140422218143104 -> 140422218141760
	140422216753376 [label="layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140422216753376 -> 140422218143104
	140422218143104 [label=AccumulateGrad]
	140422218143536 -> 140422218142384
	140422216756336 [label="layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	140422216756336 -> 140422218143536
	140422218143536 [label=AccumulateGrad]
	140422218143392 -> 140422218142384
	140422216756816 [label="layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	140422216756816 -> 140422218143392
	140422218143392 [label=AccumulateGrad]
	140422218145600 -> 140422218144880
	140422216754416 [label="layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	140422216754416 -> 140422218145600
	140422218145600 [label=AccumulateGrad]
	140422218141856 -> 140422218143632
	140422216754256 [label="layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	140422216754256 -> 140422218141856
	140422218141856 [label=AccumulateGrad]
	140422218143584 -> 140422218143632
	140422216754656 [label="layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	140422216754656 -> 140422218143584
	140422218143584 [label=AccumulateGrad]
	140422218144544 -> 140422033946272
	140422032393216 -> 140422032582544
	140422032393216 [label=TBackward0]
	140422032100176 -> 140422032393216
	140422216756096 [label="fc.weight
 (1000, 2048)" fillcolor=lightblue]
	140422216756096 -> 140422032100176
	140422032100176 [label=AccumulateGrad]
	140422032582544 -> 140422218542032
}
